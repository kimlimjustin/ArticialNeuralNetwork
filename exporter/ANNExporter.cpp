//-------------------------------------------------------------
//【文件名】ANNExporter.cpp
//【功能模块和目的】ANN格式神经网络模型导出器实现
//【开发者及日期】林钲凯 2025-07-27
//【更改记录】
//-------------------------------------------------------------

#include "ANNExporter.hpp"
#include "../model/activation_functions/ActivationFunction.hpp"
#include "../utils/FileUtils.hpp"
#include <iomanip>
#include <sstream>

using namespace std;

//-------------------------------------------------------------
//【函数名称】ANNExporter
//【函数功能】构造函数
//【参数】无
//【返回值】无
//【开发者及日期】林钲凯 2025-07-27
//【更改记录】
//-------------------------------------------------------------
ANNExporter::ANNExporter() {
}

//-------------------------------------------------------------
//【函数名称】~ANNExporter
//【函数功能】析构函数
//【参数】无
//【返回值】无
//【开发者及日期】林钲凯 2025-07-27
//【更改记录】
//-------------------------------------------------------------
ANNExporter::~ANNExporter() = default;

//-------------------------------------------------------------
//【函数名称】exportNetwork
//【函数功能】导出神经网络到文件
//【参数】network：网络引用，filename：文件名
//【返回值】bool，是否导出成功
//【开发者及日期】林钲凯 2025-07-27
//【更改记录】
//-------------------------------------------------------------
bool ANNExporter::exportNetwork(const Network& network, const string& filename) {
    if (!isFormatSupported(filename)) {
        return false;
    }
    
    if (!validateNetworkForExport(network)) {
        return false;
    }
    
    ofstream file(filename);
    if (!file.is_open()) {
        return false;
    }
    
    try {
        // Write file header
        writeComment(file, "ANN Neural Network File");
        writeComment(file, "Generated by ANN Exporter");
        file << endl;
        
        // Write network header
        if (!writeNetworkHeader(file, network)) {
            return false;
        }
        
        // Write layer information
        if (!writeLayerInformation(file, network)) {
            return false;
        }
        
        // Write connections
        if (!writeConnections(file, network)) {
            return false;
        }
        
        file.close();
        return true;
    }
    catch (const exception&) {
        return false;
    }
}

//-------------------------------------------------------------
//【函数名称】getSupportedExtensions
//【函数功能】获取支持的文件扩展名
//【参数】无
//【返回值】支持的文件扩展名字符串
//【开发者及日期】林钲凯 2025-07-27
//【更改记录】
//-------------------------------------------------------------
string ANNExporter::getSupportedExtensions() const {
    return ".ann";
}

//-------------------------------------------------------------
//【函数名称】getExporterName
//【函数功能】获取导出器名称
//【参数】无
//【返回值】导出器名称字符串
//【开发者及日期】林钲凯 2025-07-27
//【更改记录】
//-------------------------------------------------------------
string ANNExporter::getExporterName() const {
    return "ANN Exporter";
}

//-------------------------------------------------------------
//【函数名称】writeNetworkHeader
//【函数功能】写入网络头信息
//【参数】file：文件流，network：网络引用
//【返回值】bool，是否写入成功
//【开发者及日期】林钲凯 2025-07-27
//【更改记录】
//-------------------------------------------------------------
bool ANNExporter::writeNetworkHeader(ofstream& file, const Network& network) {
    writeComment(file, network.getName());
    file << "G " << network.getName() << endl;
    return file.good();
}

//-------------------------------------------------------------
//【函数名称】writeLayerInformation
//【函数功能】写入层信息
//【参数】file：文件流，network：网络引用
//【返回值】bool，是否写入成功
//【开发者及日期】林钲凯 2025-07-27
//【更改记录】
//-------------------------------------------------------------
bool ANNExporter::writeLayerInformation(ofstream& file, const Network& network) {
    writeComment(file, "Six Neurons: zero bias, without activation function");
    
    // First, write all neurons
    int iNeuronIndex = 0;
    for (int iLayerIdx = 0; iLayerIdx < network.getLayerCount(); ++iLayerIdx) {
        const Layer* pLayer = network.getLayer(iLayerIdx);
        if (!pLayer) {
            return false;
        }
        
        for (int iNeuronIdx = 0; iNeuronIdx < pLayer->getNeuronCount(); ++iNeuronIdx) {
            const Neuron* pNeuron = pLayer->getNeuron(iNeuronIdx);
            if (!pNeuron) {
                return false;
            }
            
            // Write neuron: N bias activation_type
            file << "N " << fixed << setprecision(1) << pNeuron->getBias() << " ";
            
            // Determine activation type based on function name
            const ActivationFunction* pActivationFunc = pNeuron->getActivationFunction();
            int iActivationType = 0; // Default to linear
            if (pActivationFunc) {
                string name = pActivationFunc->getName();
                if (name == "Linear") {
                    iActivationType = 0;
                } else if (name == "Sigmoid") {
                    iActivationType = 1;
                } else if (name == "Tanh") {
                    iActivationType = 2;
                } else if (name == "ReLU") {
                    iActivationType = 3;
                } else {
                    iActivationType = 0; // Default to linear for unknown types
                }
            }
            file << iActivationType << endl;
            
            iNeuronIndex++;
        }
    }
    
    // Then, write layer definitions
    iNeuronIndex = 0;
    for (int iLayerIdx = 0; iLayerIdx < network.getLayerCount(); ++iLayerIdx) {
        const Layer* layer = network.getLayer(iLayerIdx);
        if (!layer) {
            return false;
        }
        
        writeComment(file, "Layer " + to_string(iLayerIdx) + ": Neuron " + 
                    to_string(iNeuronIndex) + " to " + 
                    to_string(iNeuronIndex + layer->getNeuronCount() - 1));
        
        int iStartNeuron = iNeuronIndex;
        int iEndNeuron = iNeuronIndex + layer->getNeuronCount() - 1;
        file << "L " << iStartNeuron << " " << iEndNeuron << endl;
        
        iNeuronIndex += layer->getNeuronCount();
    }
    
    return file.good();
}

//-------------------------------------------------------------
//【函数名称】writeNeuronInformation
//【函数功能】写入神经元信息
//【参数】file：文件流，layer：层引用
//【返回值】bool，是否写入成功
//【开发者及日期】林钲凯 2025-07-27
//【更改记录】
//-------------------------------------------------------------
bool ANNExporter::writeNeuronInformation(ofstream& file, const Layer& layer) {
    for (int iNeuronIdx = 0; iNeuronIdx < layer.getNeuronCount(); ++iNeuronIdx) {
        const Neuron* neuron = layer.getNeuron(iNeuronIdx);
        if (!neuron) {
            return false;
        }
        
        file << "NEURON " << fixed << setprecision(6) << neuron->getBias();
        
        const ActivationFunction* activationFunc = neuron->getActivationFunction();
        if (activationFunc) {
            file << " ACTIVATION " << getActivationFunctionName(activationFunc);
        }
        
        file << endl;
    }
    
    return file.good();
}

//-------------------------------------------------------------
//【函数名称】writeConnections
//【函数功能】写入连接信息
//【参数】file：文件流，network：网络引用
//【返回值】bool，是否写入成功
//【开发者及日期】林钲凯 2025-07-27
//【更改记录】
//-------------------------------------------------------------
bool ANNExporter::writeConnections(ofstream& file, const Network& network) {
    // First write input connections (from external input to first layer)
    const Layer* firstLayer = network.getLayer(0);
    if (firstLayer) {
        writeComment(file, "Neuron 0 to " + to_string(firstLayer->getNeuronCount() - 1) + ": has one Dendrite");
        for (int iNeuronIdx = 0; iNeuronIdx < firstLayer->getNeuronCount(); ++iNeuronIdx) {
            const Neuron* neuron = firstLayer->getNeuron(iNeuronIdx);
            if (neuron && neuron->getInputSynapseCount() > 0) {
                // Find the input synapse with source = nullptr (external input)
                for (int iSynapseIdx = 0; iSynapseIdx < neuron->getInputSynapseCount(); ++iSynapseIdx) {
                    const Synapse* synapse = neuron->getInputSynapse(iSynapseIdx);
                    if (synapse && synapse->getSourceNeuron() == nullptr) {
                        file << "S -1 " << iNeuronIdx << " " << fixed << setprecision(1) 
                             << synapse->getWeight() << endl;
                        break;
                    }
                }
            }
        }
    }
    
    // Write output connections (from last layer to external output)
    const Layer* lastLayer = network.getLayer(network.getLayerCount() - 1);
    if (lastLayer) {
        int iLastLayerStart = 0;
        for (int iLayerIdx = 0; iLayerIdx < network.getLayerCount() - 1; ++iLayerIdx) {
            const Layer* layer = network.getLayer(iLayerIdx);
            if (layer) {
                iLastLayerStart += layer->getNeuronCount();
            }
        }
        
        writeComment(file, "Neuron " + to_string(iLastLayerStart) + " to " + 
                    to_string(iLastLayerStart + lastLayer->getNeuronCount() - 1) + ": has one Axon");
        for (int iNeuronIdx = 0; iNeuronIdx < lastLayer->getNeuronCount(); ++iNeuronIdx) {
            const Neuron* neuron = lastLayer->getNeuron(iNeuronIdx);
            if (neuron && neuron->getOutputSynapseCount() > 0) {
                // Find the output synapse with target = nullptr (external output)
                for (int iSynapseIdx = 0; iSynapseIdx < neuron->getOutputSynapseCount(); ++iSynapseIdx) {
                    const Synapse* synapse = neuron->getOutputSynapse(iSynapseIdx);
                    if (synapse && synapse->getTargetNeuron() == nullptr) {
                        file << "S " << (iLastLayerStart + iNeuronIdx) << " -1 " << fixed << setprecision(1) 
                             << synapse->getWeight() << endl;
                        break;
                    }
                }
            }
        }
    }
    
    // Write inter-layer connections
    int iCurrentNeuronOffset = 0;
    for (int iLayerIndex = 0; iLayerIndex < network.getLayerCount(); ++iLayerIndex) {
        const Layer* layer = network.getLayer(iLayerIndex);
        if (!layer) continue;
        
        for (int iNeuronIdx = 0; iNeuronIdx < layer->getNeuronCount(); ++iNeuronIdx) {
            const Neuron* pNeuron = layer->getNeuron(iNeuronIdx);
            if (!pNeuron) continue;
            
            int iGlobalNeuronIndex = iCurrentNeuronOffset + iNeuronIdx;
            
            // Write output connections for this neuron
            if (pNeuron->getOutputSynapseCount() > 0) {
                // Find target layer neurons
                int iTargetLayerStart = iCurrentNeuronOffset + layer->getNeuronCount();
                
                // Add comment for this neuron's connections if it's not the last layer
                if (iLayerIndex < network.getLayerCount() - 1) {
                    const Layer* nextLayer = network.getLayer(iLayerIndex + 1);
                    if (nextLayer) {
                        writeComment(file, "Dendrites from Neuron " + to_string(iGlobalNeuronIndex) + 
                                    " to Neuron " + to_string(iTargetLayerStart) + "~" + 
                                    to_string(iTargetLayerStart + nextLayer->getNeuronCount() - 1));
                    }
                }
                
                for (int iSynapseIndex = 0; iSynapseIndex < pNeuron->getOutputSynapseCount(); ++iSynapseIndex) {
                    const Synapse* pSynapse = pNeuron->getOutputSynapse(iSynapseIndex);
                    if (!pSynapse) continue;
                    
                    const Neuron* pTargetNeuron = pSynapse->getTargetNeuron();
                    if (!pTargetNeuron) continue;
                    
                    // Find the global index of the target neuron
                    int iTargetGlobalIndex = findNeuronGlobalIndex(network, pTargetNeuron);
                    if (iTargetGlobalIndex >= 0) {
                        // 根据规范：轴突权重恒为1.0，实际连接权重存储在目标神经元的树突中
                        // 找到目标神经元中对应的输入突触（树突）来获取实际权重
                        double rConnectionWeight = 1.0; // 默认权重
                        for (int iInputIdx = 0; iInputIdx < pTargetNeuron->getInputSynapseCount(); ++iInputIdx) {
                            const Synapse* pInputSynapse = pTargetNeuron->getInputSynapse(iInputIdx);
                            if (pInputSynapse && pInputSynapse->getSourceNeuron() == pNeuron) {
                                rConnectionWeight = pInputSynapse->getWeight();
                                break;
                            }
                        }
                        
                        file << "S " << iGlobalNeuronIndex << " " << iTargetGlobalIndex 
                             << " " << fixed << setprecision(4) << rConnectionWeight 
                             << endl;
                    }
                }
            }
        }
        
        iCurrentNeuronOffset += layer->getNeuronCount();
    }
    
    return file.good();
}

//-------------------------------------------------------------
//【函数名称】writeComment
//【函数功能】写入注释
//【参数】file：文件流，comment：注释内容
//【返回值】无
//【开发者及日期】林钲凯 2025-07-27
//【更改记录】
//-------------------------------------------------------------
void ANNExporter::writeComment(ofstream& file, const string& comment) {
    file << "# " << comment << endl;
}

//-------------------------------------------------------------
//【函数名称】getActivationFunctionName
//【函数功能】获取激活函数名称
//【参数】activationFunction：激活函数指针
//【返回值】激活函数名称字符串
//【开发者及日期】林钲凯 2025-07-27
//【更改记录】
//-------------------------------------------------------------
string ANNExporter::getActivationFunctionName(const ActivationFunction* activationFunction) const {
    if (!activationFunction) {
        return "Linear";
    }
    return activationFunction->getName();
}

//-------------------------------------------------------------
//【函数名称】findNeuronGlobalIndex
//【函数功能】查找神经元的全局索引
//【参数】network：网络引用，targetNeuron：目标神经元指针
//【返回值】int，全局索引，未找到返回-1
//【开发者及日期】林钲凯 2025-07-27
//【更改记录】
//-------------------------------------------------------------
int ANNExporter::findNeuronGlobalIndex(const Network& network, const Neuron* targetNeuron) {
    int iGlobalIndex = 0;
    
    for (int iLayerIndex = 0; iLayerIndex < network.getLayerCount(); ++iLayerIndex) {
        const Layer* layer = network.getLayer(iLayerIndex);
        if (!layer) continue;
        
        for (int iNeuronIdx = 0; iNeuronIdx < layer->getNeuronCount(); ++iNeuronIdx) {
            if (layer->getNeuron(iNeuronIdx) == targetNeuron) {
                return iGlobalIndex;
            }
            iGlobalIndex++;
        }
    }
    
    return -1; // Not found
}
